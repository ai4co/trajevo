{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x74af3adda110>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate time\n",
    "import time\n",
    "\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from trajectory_prediction.utils import (\n",
    "    compute_batch_ade_ret,\n",
    "    compute_batch_fde_ret,\n",
    "    get_dataloader,\n",
    ")\n",
    "\n",
    "# fix random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here: put original predict_trajectory function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def predict_trajectory(trajectory: np.ndarray, sample=True) -> np.ndarray:\n",
    "    \"\"\"Generate 20 diverse possible future trajectories using constant velocity model with stochastic sampling.\n",
    "\n",
    "    Args:\n",
    "        trajectory (np.ndarray): Input trajectory of shape [num_agents, traj_length, 2], where traj_length is 8.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of 20 diverse trajectories of shape [20, num_agents, 12, 2].\n",
    "    \"\"\"\n",
    "    # Convert numpy array to torch tensor for compatibility with reference code\n",
    "    trajectory_torch = torch.tensor(trajectory, dtype=torch.float32)\n",
    "    num_agents = trajectory.shape[0]\n",
    "\n",
    "    # Parameters from the reference code\n",
    "    num_samples = 20\n",
    "    sample_angle_std = 25  # Standard deviation for angle sampling in degrees\n",
    "\n",
    "    all_trajectories = []\n",
    "\n",
    "    # For each sample\n",
    "    for _ in range(num_samples):\n",
    "        # Sample one angle for all agents in this trajectory sample\n",
    "        if sample:\n",
    "            sampled_angle = np.random.normal(0, sample_angle_std, 1)[0]\n",
    "        else:\n",
    "            sampled_angle = 0\n",
    "\n",
    "        theta = (sampled_angle * np.pi) / 180.0\n",
    "        c, s = np.cos(theta), np.sin(theta)\n",
    "        rotation_mat = torch.tensor([[c, s], [-s, c]], dtype=torch.float32)\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for agent_idx in range(num_agents):\n",
    "            # Get observed trajectory for current agent\n",
    "            observed = trajectory_torch[agent_idx].unsqueeze(0)  # [1, 8, 2]\n",
    "\n",
    "            # Calculate relative movement (similar to obs_rel in the reference)\n",
    "            obs_rel = observed[:, 1:] - observed[:, :-1]  # [1, 7, 2]\n",
    "\n",
    "            # Use the last velocity as constant velocity\n",
    "            last_velocity = obs_rel[:, -1].unsqueeze(1)  # [1, 1, 2]\n",
    "\n",
    "            # Apply rotation to the velocity (using the same rotation for all agents)\n",
    "            vel = last_velocity.squeeze(dim=0).squeeze(dim=0)  # [2]\n",
    "            rotated_vel = torch.matmul(rotation_mat, vel)  # [2]\n",
    "            rotated_vel = rotated_vel.unsqueeze(0).unsqueeze(0)  # [1, 1, 2]\n",
    "\n",
    "            # Create 12 predictions with the constant (rotated) velocity\n",
    "            pred_rel = rotated_vel.repeat(1, 12, 1)  # [1, 12, 2]\n",
    "\n",
    "            # Convert to absolute positions (cumulative sum + start position)\n",
    "            displacement = torch.cumsum(pred_rel, dim=1)  # [1, 12, 2]\n",
    "            start_pos = observed[:, -1].unsqueeze(1)  # [1, 1, 2]\n",
    "            pred_abs = displacement + start_pos  # [1, 12, 2]\n",
    "\n",
    "            predictions.append(pred_abs.squeeze(0).numpy())  # [12, 2]\n",
    "\n",
    "        # Stack all agent predictions for this sample\n",
    "        sample_prediction = np.stack(predictions, axis=0)  # [num_agents, 12, 2]\n",
    "        all_trajectories.append(sample_prediction)\n",
    "\n",
    "    # Stack all samples\n",
    "    result = np.stack(all_trajectories, axis=0)  # [20, num_agents, 12, 2]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put new trajectory prediction function here (optimized by AI afterwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def predict_trajectory_optimized(trajectory: np.ndarray, sample=True) -> np.ndarray:\n",
    "    \"\"\"Generate 20 diverse possible future trajectories using constant velocity model with stochastic sampling.\n",
    "\n",
    "    Args:\n",
    "        trajectory (np.ndarray): Input trajectory of shape [num_agents, traj_length, 2], where traj_length is 8.\n",
    "        sample (bool): Whether to apply random rotation sampling.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of 20 diverse trajectories of shape [20, num_agents, 12, 2].\n",
    "    \"\"\"\n",
    "    num_agents = trajectory.shape[0]\n",
    "    num_samples = 20\n",
    "    sample_angle_std = 25  # Standard deviation for angle sampling in degrees\n",
    "\n",
    "    # Calculate relative movement for all agents at once\n",
    "    obs_rel = trajectory[:, 1:] - trajectory[:, :-1]  # [num_agents, 7, 2]\n",
    "\n",
    "    # Get last velocity for all agents\n",
    "    last_velocity = obs_rel[:, -1]  # [num_agents, 2]\n",
    "\n",
    "    # Starting positions for all agents\n",
    "    start_pos = trajectory[:, -1]  # [num_agents, 2]\n",
    "\n",
    "    # Pre-allocate result array\n",
    "    result = np.zeros((num_samples, num_agents, 12, 2))\n",
    "\n",
    "    # Generate all samples\n",
    "    for sample_idx in range(num_samples):\n",
    "        # Sample one angle for this trajectory sample\n",
    "        if sample:\n",
    "            sampled_angle = np.random.normal(0, sample_angle_std, 1)[0]\n",
    "        else:\n",
    "            sampled_angle = 0\n",
    "\n",
    "        theta = (sampled_angle * np.pi) / 180.0\n",
    "        c, s = np.cos(theta), np.sin(theta)\n",
    "        rotation_mat = np.array([[c, s], [-s, c]])\n",
    "\n",
    "        # For each agent\n",
    "        for agent_idx in range(num_agents):\n",
    "            vel = last_velocity[agent_idx]  # [2]\n",
    "\n",
    "            # Apply rotation\n",
    "            rotated_vel = np.dot(rotation_mat, vel)  # [2]\n",
    "\n",
    "            # Create predictions with constant rotated velocity\n",
    "            pred_rel = np.tile(rotated_vel, (12, 1))  # [12, 2]\n",
    "\n",
    "            # Convert to absolute positions (cumulative sum + start position)\n",
    "            displacement = np.cumsum(pred_rel, axis=0)  # [12, 2]\n",
    "            result[sample_idx, agent_idx] = displacement + start_pos[agent_idx]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if they are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: ETH\n",
      "Original ADE: 0.9307\n",
      "Original FDE: 2.0142\n",
      "New ADE: 0.9210\n",
      "New FDE: 2.0101\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAJECTORIES = 20 # expected for minADE20\n",
    "\n",
    "obs_len = 8\n",
    "pred_len = 12\n",
    "batch_size = 32\n",
    "\n",
    "# datasets = [\"eth\", \"hotel\", \"univ\", \"zara1\", \"zara2\"]\n",
    "datasets = [\"eth\"]\n",
    "# datasets = [\"hotel\"]\n",
    "# datasets = [\"zara1\"]\n",
    "\n",
    "dataset_name = \"eth\"\n",
    "print(f\"\\nProcessing dataset: {dataset_name.upper()}\")\n",
    "\n",
    "dataset_dir = path.join(\"datasets\", dataset_name)\n",
    "\n",
    "loader_test = get_dataloader(dataset_dir, 'test', 8, 12, batch_size=1)\n",
    "\n",
    "original_ade = []\n",
    "original_fde = []\n",
    "new_ade = []\n",
    "new_fde = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for i, batch in enumerate(loader_test):\n",
    "        input_traj = batch[0].numpy()  # [num_agents, obs_len, 2]\n",
    "        target_traj = batch[1].numpy()  # [num_agents, pred_len, 2]\n",
    "\n",
    "        gpt_prediction = predict_trajectory_optimized(input_traj)\n",
    "        gpt_prediction_original = predict_trajectory(input_traj)\n",
    "        # assert np.allclose(gpt_prediction, gpt_prediction_original), f\"Prediction mismatch at batch {i}\"\n",
    "        # manual way , we can hust check final result too\n",
    "\n",
    "        original_ade.append(compute_batch_ade_ret(torch.tensor(gpt_prediction_original), torch.tensor(target_traj))[0])\n",
    "        original_fde.append(compute_batch_fde_ret(torch.tensor(gpt_prediction_original), torch.tensor(target_traj))[0])\n",
    "        new_ade.append(compute_batch_ade_ret(torch.tensor(gpt_prediction), torch.tensor(target_traj))[0])\n",
    "        new_fde.append(compute_batch_fde_ret(torch.tensor(gpt_prediction), torch.tensor(target_traj))[0])\n",
    "\n",
    "print(f\"Original ADE: {torch.stack(original_ade).mean().item():.4f}\")\n",
    "print(f\"Original FDE: {torch.stack(original_fde).mean().item():.4f}\")\n",
    "print(f\"New ADE: {torch.stack(new_ade).mean().item():.4f}\")\n",
    "print(f\"New FDE: {torch.stack(new_fde).mean().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main testing loop (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: ETH\n",
      "Average time: 2.077040910720825 seconds\n",
      "Time per test: 0.20770409107208251 seconds\n",
      "Time per instance: 0.00296720130102975 seconds\n",
      "Time per instance: 2967.20130102975 microseconds\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAJECTORIES = 20 # expected for minADE20\n",
    "\n",
    "dataset_name = \"eth\"\n",
    "print(f\"\\nProcessing dataset: {dataset_name.upper()}\")\n",
    "\n",
    "dataset_dir = path.join(\"datasets\", dataset_name)\n",
    "\n",
    "loader_test = get_dataloader(dataset_dir, 'test', obs_len, pred_len, batch_size=1)\n",
    "\n",
    "\n",
    "num_tests = 10\n",
    "\n",
    "total_times = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(num_tests):\n",
    "        start_time = time.time()\n",
    "        for i, batch in enumerate(loader_test):\n",
    "            input_traj = batch[0].numpy()  # [num_agents, obs_len, 2]\n",
    "            target_traj = batch[1].numpy()  # [num_agents, pred_len, 2]\n",
    "\n",
    "            # Eval optimized model time\n",
    "            # gpt_prediction = predict_trajectory_optimized(input_traj)\n",
    "\n",
    "            # Eval original model time\n",
    "            gpt_prediction = predict_trajectory(input_traj)\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_times.append(end_time - start_time)\n",
    "\n",
    "\n",
    "# print average time\n",
    "print(f\"Average time: {np.sum(total_times)} seconds\")\n",
    "# time per test\n",
    "print(f\"Time per test: {np.mean(total_times)} seconds\")\n",
    "# time per instnace\n",
    "print(f\"Time per instance: {np.mean(total_times) / len(loader_test)} seconds\")\n",
    "\n",
    "# print the microseconds\n",
    "print(f\"Time per instance: {np.mean(total_times) / len(loader_test) * 1e6} microseconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: ETH\n",
      "Average time: 0.6356363296508789 seconds\n",
      "Time per test: 0.0635636329650879 seconds\n",
      "Time per instance: 0.0009080518995012556 seconds\n",
      "Time per instance: 908.0518995012555 microseconds\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAJECTORIES = 20 # expected for minADE20\n",
    "\n",
    "dataset_name = \"eth\"\n",
    "print(f\"\\nProcessing dataset: {dataset_name.upper()}\")\n",
    "\n",
    "dataset_dir = path.join(\"datasets\", dataset_name)\n",
    "\n",
    "loader_test = get_dataloader(dataset_dir, 'test', obs_len, pred_len, batch_size=1)\n",
    "\n",
    "\n",
    "num_tests = 10\n",
    "\n",
    "total_times = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for _ in range(num_tests):\n",
    "        start_time = time.time()\n",
    "        for i, batch in enumerate(loader_test):\n",
    "            input_traj = batch[0].numpy()  # [num_agents, obs_len, 2]\n",
    "            target_traj = batch[1].numpy()  # [num_agents, pred_len, 2]\n",
    "\n",
    "            # Eval optimized model time\n",
    "            gpt_prediction = predict_trajectory_optimized(input_traj)\n",
    "\n",
    "            # Eval original model time\n",
    "            # gpt_prediction = predict_trajectory(input_traj)\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_times.append(end_time - start_time)\n",
    "\n",
    "\n",
    "# print average time\n",
    "print(f\"Average time: {np.sum(total_times)} seconds\")\n",
    "# time per test\n",
    "print(f\"Time per test: {np.mean(total_times)} seconds\")\n",
    "# time per instnace\n",
    "print(f\"Time per instance: {np.mean(total_times) / len(loader_test)} seconds\")\n",
    "\n",
    "# print the microseconds\n",
    "print(f\"Time per instance: {np.mean(total_times) / len(loader_test) * 1e6} microseconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
